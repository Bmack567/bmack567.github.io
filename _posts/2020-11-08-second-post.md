---
layout: post
title: 2. Imagining Image-Literate Computers
---

We recently discussed machine learning and artificial intelligence in our lectures. When we design "stupid" computers to organize our data, they reveal new perspectives about the structures of text that are buried behind a distracting layer of meaning. By asking a computer to read hundreds of novels and then write its own, we can see similarities between texts that verify the conventional norms of the genre. Can the same ever be done for comics? If machine learning can allow computers to write novels, can they be taught to draw pictures?

At the moment, image recognition software is fairly unreliable. This is why CAPTCHA works, for example. Computers struggle to distinguish between overlapping shapes. If this current technology so frequently struggles to recognize typeset text, how could we expect it to "read" elements of a picture as distinct, and then translate them into categories of data?

Although we don't have access yet to the data, digital humanities can allow us to think about how else we can approach this issue. If we were to *imagine* the result of a machine produced comic, what would it look like? What could this tell us about the innate structures of comics pages? If we our dataset consists of the developing canon of comics studies, we might expect a simulation to emphasize panels, vaguely humanoid characters distinct from their backgrounds, and consistent textual overlays. 

The infinite variability of Penrose tiling might offer the key to theorizing image recognition. Penrose tiling is a design theory in which "tiles" of limited shapes are mathematically arranged to cover an infinite plane with infinite, non-repeating patterns. If a computer can be taught to recognized patterns of tiling because of their mathematical properties despite their infinite variation, perhaps they can be taught to recognize the mathematical similarities of similar but non-identical drawings. The potential motifs we can expect an image-trained computer to recreate show us that images apply rules and repeated structures not unlike those visible in traditional novels. If we compare these to the rules which dictate Penrose tiling, we can see historical precedent of a mathematically-derived sequence of infinite, distinct images. If a computer can be taught to recognize segments of Penrose tiling, perhaps this logic can train them to read images.

If we think of every word in the dictionary as our dataset, we can imagine that for every word is an infinite series of possible images that can be used to describe it. We know, however, that the number of possible images must be less than infinite, as an image that corresponds perfectly to the word "boat" would be very unlikely to also correspond to the word "fettucine." Therefore, there must be a finite number of ways to visually express "boat." There are also common features shared by various images which can be used to express this word. By teaching enough of these varieties to a computer, it can then learn to recognize the familiar shapes that resemble words. This is the logic applied by Google's Quick, Draw! application which publicly requests that users draw images for corresponding words and add them to "the world's largest doodling data set, shared publicly to help with machine learning research." Google's project is demonstrating that modern computers can begin to recognize drawings by following similar principles to text recognition. 

How far can we imagine the future of image recognition? Could an algorithm be designed to detect stolen material from other artists? Then, of course, who would be notified and who has the authority to remove content? And could such technology be sensitive enough to detect similarities that aren't exact copies? As always, attempting to answer questions only leads to further questions. But imagining potential results allows us to bypass obstacles and ask new kinds of questions about forms of media. What would we *expect* a comic to look like if it were machine-generated? Our answers to this question might be just as productive as asking a machine to perform the same tasks.